{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng to Mng-v2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "D7Tq6bpRhOAr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WaGTLMxVhf2K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wHmdoyURhjcg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gBCma92Whq0S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Zа-яА-ЯӨҮөүёЁ.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gjCR7mmfhvgA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    #lines = pd.read_excel('finaleng-mon.xlsx')\n",
        "    lines = pd.read_excel('/content/drive/My Drive/UIC/IDS576/Project/finaleng-mon.xlsx')\n",
        "    pairs = []\n",
        "    for i, l in lines.iterrows():\n",
        "        pairs.append([normalizeString(l[0]), normalizeString(l[1])])\n",
        "    \n",
        "    lang1 = \"eng\"\n",
        "    lang2 = \"mon\"\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    #pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sgdp9UcRpaCn",
        "colab_type": "code",
        "outputId": "0462c288-fc01-4cd3-8e90-b6a344a9f17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yAac9jZLhwzg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 8\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH #and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vWUyNX2Yh1XW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BQ-bSi53h5S5",
        "outputId": "4d8941d4-dee6-479c-9c7a-f866229964c3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'mon', False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 1040 sentence pairs\n",
            "Trimmed to 1038 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 1018\n",
            "mon 1410\n",
            "['you re extremely ingenious .', 'чи үнэхээр их мэргэн ухаантай юм .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mdb4i_MmoKkW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        return outputs, hidden\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fdiPnwuZokJC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2))) \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qYN_ryx-pAR0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim=1))\n",
        "        \n",
        "        return output, hidden.squeeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lXM_sLzdpdiQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "    \n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        output = trg[0,:]\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2-BMJba1pwsg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = input_lang.n_words\n",
        "OUTPUT_DIM = output_lang.n_words\n",
        "ENC_EMB_DIM = 128 #256\n",
        "DEC_EMB_DIM = 128 #256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6ieK7dYIp3wt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wklN5ycRp4YB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H8LdNOIAlAvx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hm76EgfiqYZj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, n_iters, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    \n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        src = training_pair[0]\n",
        "        trg = training_pair[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / n_iters\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Sh_GTgr1qc_s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, n_iters, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "        \n",
        "        for iter in range(1, n_iters + 1):\n",
        "            training_pair = training_pairs[iter - 1]\n",
        "            src = training_pair[0]\n",
        "            trg = training_pair[1]\n",
        "            \n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / n_iters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "emVOr36dqlKh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MWUqE_7UqoeA",
        "outputId": "281578c5-8914-4228-86c3-40a9cac9dada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "SAVE_DIR = 'models'\n",
        "  \n",
        "MODEL_SAVE_PATH = '/content/drive/My Drive/UIC/IDS576/Project/engmon_model.pt'\n",
        "#MODEL_SAVE_PATH = 'engmon_model.pt'\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "n_iters = min(5000, len(pairs))\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, n_iters, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, n_iters, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 22s\n",
            "\tTrain Loss: 4.440 | Train PPL:  84.742\n",
            "\t Val. Loss: 4.032 |  Val. PPL:  56.396\n",
            "Epoch: 02 | Time: 0m 23s\n",
            "\tTrain Loss: 3.186 | Train PPL:  24.195\n",
            "\t Val. Loss: 3.335 |  Val. PPL:  28.088\n",
            "Epoch: 03 | Time: 0m 22s\n",
            "\tTrain Loss: 2.336 | Train PPL:  10.338\n",
            "\t Val. Loss: 2.651 |  Val. PPL:  14.172\n",
            "Epoch: 04 | Time: 0m 22s\n",
            "\tTrain Loss: 1.778 | Train PPL:   5.917\n",
            "\t Val. Loss: 2.061 |  Val. PPL:   7.855\n",
            "Epoch: 05 | Time: 0m 23s\n",
            "\tTrain Loss: 1.365 | Train PPL:   3.915\n",
            "\t Val. Loss: 1.626 |  Val. PPL:   5.085\n",
            "Epoch: 06 | Time: 0m 22s\n",
            "\tTrain Loss: 1.111 | Train PPL:   3.036\n",
            "\t Val. Loss: 1.185 |  Val. PPL:   3.269\n",
            "Epoch: 07 | Time: 0m 22s\n",
            "\tTrain Loss: 0.817 | Train PPL:   2.265\n",
            "\t Val. Loss: 1.141 |  Val. PPL:   3.131\n",
            "Epoch: 08 | Time: 0m 22s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 1.017 |  Val. PPL:   2.765\n",
            "Epoch: 09 | Time: 0m 23s\n",
            "\tTrain Loss: 0.573 | Train PPL:   1.774\n",
            "\t Val. Loss: 0.772 |  Val. PPL:   2.165\n",
            "Epoch: 10 | Time: 0m 23s\n",
            "\tTrain Loss: 0.512 | Train PPL:   1.668\n",
            "\t Val. Loss: 0.641 |  Val. PPL:   1.898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iywoi6N_lY0h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(model, pair, max_length=MAX_LENGTH):\n",
        "    \n",
        "    sentence_pair = tensorsFromPair(pair)\n",
        "    \n",
        "    src = sentence_pair[0]\n",
        "    trg = sentence_pair[1]\n",
        "    #print(src)\n",
        "    output = model(src, trg, 0)\n",
        "    output = output[1:].view(-1, output.shape[-1])\n",
        "    \n",
        "    out_pred = output.data.topk(1)[1]\n",
        "\n",
        "    translation = [output_lang.index2word[word.item()] for word in out_pred]\n",
        "    \n",
        "    \n",
        "    return translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bR29ehYXlR64",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(model, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = translate(model, pair)\n",
        "        \n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L4eznZ96lajY",
        "outputId": "c37f5bcf-3c5a-4000-f02d-68cca85cd7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "cell_type": "code",
      "source": [
        "evaluateRandomly(model)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> we re just hanging out .\n",
            "= бид зүгээр л уулзаж байна .\n",
            "< зүгээр л уулзаж байна . EOS\n",
            "\n",
            "> we re quieter than tom .\n",
            "= бид томыг бодвол чимээгүй байна .\n",
            "< томыг бодвол чимээгүй байна . EOS\n",
            "\n",
            "> we re friends of tom s .\n",
            "= бид томын найзууд .\n",
            "< томын найзууд . EOS\n",
            "\n",
            "> we re going to eat now .\n",
            "= бид одоо идэх гэж байна .\n",
            "< одоо идэх гэж байна . EOS\n",
            "\n",
            "> he is rather hard to please .\n",
            "= тэр үнэндээ цамаан .\n",
            "< үнэндээ цамаан . EOS\n",
            "\n",
            "> you re under my protection .\n",
            "= чи миний хамгаалалт доор байна .\n",
            "< миний хамгаалалт доор байна . EOS\n",
            "\n",
            "> she s the most beautiful woman .\n",
            "= тэр бол хамгийн үзэсгэлэнтэй эмэгтэй .\n",
            "< бол хамгийн үзэсгэлэнтэй . EOS EOS\n",
            "\n",
            "> they are not at all interested .\n",
            "= тэд бүгдийг нь сонирхохгүй байна .\n",
            "< бүгдийг нь сонирхохгүй . EOS EOS\n",
            "\n",
            "> i m getting married next month .\n",
            "= би дараа сард гэрлэнэ .\n",
            "< дараа сард гэрлэнэ . EOS\n",
            "\n",
            "> i m not making any promises .\n",
            "= би ямар нэг амлалт өгөхгүй .\n",
            "< ямар нэг амлалт өгөхгүй . EOS\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5dhxRKIXn5tF",
        "colab_type": "code",
        "outputId": "df54a9d9-37f3-42a8-e62d-a2b8801e18ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "translate(model, ['you re working hard .', 'чи шаргуу ажиллаж байна . '])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['одоо', 'шаргуу', 'ажиллаж', 'байна', '.', 'EOS']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "BRCUeYlgn5tJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}